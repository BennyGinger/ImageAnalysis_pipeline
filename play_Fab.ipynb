{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform mask into COSTO .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os import listdir, PathLike\n",
    "from os.path import join\n",
    "from pipeline.image_handeling.data_utility import load_stack\n",
    "from skimage.measure import find_contours, regionprops_table\n",
    "from numpyencoder import NumpyEncoder\n",
    "import json\n",
    "\n",
    "def mask_to_json(mask_fold_path: PathLike, save_path: PathLike, channel:str)->None:\n",
    "  \"\"\"Function that converts .tif labeled masks from np.array stacks into COCO .json format files.\n",
    "  Saves the file into the given location.\n",
    "  Args:\n",
    "      mask_fold_path (PathLike): Folder of the masks.\n",
    "      save_path (PathLike): Path where the .json is going to be saved. Must include the filename and the ending \".json\".\n",
    "      channel (string): The channel that should be transformed into .json.\n",
    "  Returns:\n",
    "      None, saves the .json into the given location.\"\"\"\n",
    "  img_path = []\n",
    "  for file in sorted(listdir(mask_fold_path)):\n",
    "      if channel in file:\n",
    "        img_path.append(join(mask_fold_path,file))\n",
    "  im_num = re.findall('f\\d+', str(img_path))\n",
    "  max_number = max(int(x[1:]) for x in im_num)\n",
    "  max_number\n",
    "\n",
    "  img_stack = load_stack(img_paths=img_path, channels=channel, frame_range=range(max_number), return_2D=True)\n",
    "\n",
    "  annotations_lst = []\n",
    "  images_lst = []\n",
    "  for frame, img in enumerate(img_stack):\n",
    "    outline_region =regionprops_table(img, properties=('label','bbox','area'))\n",
    "    frame_name = img_path[frame].rsplit('/',1)[1]\n",
    "    labels = outline_region['label']\n",
    "    bbox0 = outline_region['bbox-0']\n",
    "    bbox1 = outline_region['bbox-1']\n",
    "    bbox2 = outline_region['bbox-2']\n",
    "    bbox3 = outline_region['bbox-3']\n",
    "    area = outline_region['area']\n",
    "\n",
    "    for i in range(labels.shape[0]):\n",
    "        label = labels[i]\n",
    "        segmentation_lst=[]\n",
    "        regionmask=(img==label)\n",
    "        coords = find_contours(regionmask)\n",
    "        for y,x in coords[0]:\n",
    "            segmentation_lst.append(x+0.5)\n",
    "            segmentation_lst.append(y+0.5)\n",
    "        \n",
    "        annotations_lst.append({'id':label, \n",
    "                                'image_id':frame+1,\n",
    "                                'category_id':1,\n",
    "                                'segmentation':[segmentation_lst],\n",
    "                                'area':area[i],\n",
    "                                'bbox':[bbox0[i], bbox1[i], bbox2[i], bbox3[i]],\n",
    "                                'iscrowd': 0,\n",
    "                                'attributes': {'occluded': False}})\n",
    "\n",
    "    images_lst.append({'id': frame+1,\n",
    "              'width': img.shape[1],\n",
    "              'height': img.shape[0],\n",
    "              'file_name': frame_name,\n",
    "              'license': 0,\n",
    "              'flickr_url': '',\n",
    "              'coco_url': '',\n",
    "              'date_captured': 0})\n",
    "\n",
    "  json_dict = {'licenses': [{'name': '', 'id': 0, 'url': ''}],\n",
    "          'info': {'contributor': '',\n",
    "            'date_created': '',\n",
    "            'description': '',\n",
    "            'url': '',\n",
    "            'version': '',\n",
    "            'year': ''},\n",
    "          'categories': [{'id': 1, 'name': 'Cell', 'supercategory': ''}],\n",
    "          'images': images_lst,\n",
    "          'annotations':annotations_lst}\n",
    "\n",
    "  with open(save_path, \"w\") as file:\n",
    "      json.dump(json_dict, file, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mask_folder = '/home/Fabian/ImageData/TrackingTestFiles/NeutrophilTrackingTest/mfap4-mpx_isohypo_2h_WT-MaxIP_s1/Masks_Cellpose'\n",
    "channel = 'GFP'\n",
    "savefile = '/home/Fabian/ImageData/Seriestest.json'\n",
    "\n",
    "mask_to_json(mask_fold_path=mask_folder, save_path=savefile, channel=channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct mask based on COSTO .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from skimage.draw import polygon2mask\n",
    "from os import PathLike\n",
    "\n",
    "def mask_from_json(path:PathLike)->tuple[list[str],np.array]:\n",
    "    \"\"\"Recreates an np.array like stack of masks based on an COCO .json file.\n",
    "    Return the np.array stack of masks and a list fo the Mask names.\n",
    "    Args:\n",
    "        path (PathLike): Path of the .json file to be loaded.\n",
    "    Returns:\n",
    "        tuple[list[str],np.array]: List of the image names, np.array containing the loaded masks\"\"\"\n",
    "    file = open(path)\n",
    "    json_file = json.load(file)\n",
    "\n",
    "    mask_lst = []\n",
    "    name_lst = []\n",
    "    width = json_file['images'][0]['width']\n",
    "    height = json_file['images'][0]['height']\n",
    "    annotations = json_file['annotations']\n",
    "    n_frame = len(json_file['images'])\n",
    "    mask = np.zeros((n_frame,width,height), dtype='int')\n",
    "    for images in json_file['images']:\n",
    "        name_lst.append(images['file_name'])\n",
    "    for annot in annotations:\n",
    "        segmentation = annot['segmentation'][0]\n",
    "        id = int(annot['id'])\n",
    "        frame_id = int(annot['image_id'])\n",
    "        coord_lst = []\n",
    "        for point in range(0, len(segmentation),2):\n",
    "            coord_lst.append((round(segmentation[point+1]), round(segmentation[point])))\n",
    "        tempmask =  polygon2mask((width,height),coord_lst)\n",
    "        tempmask[tempmask!=0] = id\n",
    "        mask[frame_id-1] = mask[frame_id-1] + tempmask\n",
    "    mask_lst.append(mask)\n",
    "    mask_stack = np.squeeze(np.stack(mask_lst))\n",
    "    return name_lst, mask_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/Fabian/ImageData/instances_Series.json'\n",
    "name_lst, mask_stack = mask_from_json(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tifffile import imwrite\n",
    "from os import walk\n",
    "from os.path import join\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/Fabian/ImageData/CalciumImmunCell/Macrophage/Laserwound/c1147x1382_003-MaxIP_s2/Masks_Cellpose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):            \n\u001b[0;32m----> 4\u001b[0m         npy \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      5\u001b[0m         filename \u001b[38;5;241m=\u001b[39m npy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m         mask \u001b[38;5;241m=\u001b[39m npy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/cp_dock/lib/python3.8/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/opt/conda/envs/cp_dock/lib/python3.8/site-packages/numpy/lib/format.py:793\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    791\u001b[0m     pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 793\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;66;03m# Friendlier error message\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnpickling a python object failed: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    797\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may need to pass the encoding= option \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    798\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto numpy.load\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (err,)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):            \n",
    "            npy = np.load(join(root, file), allow_pickle=True).item()\n",
    "            filename = npy['filename']\n",
    "            mask = npy['masks']\n",
    "            imwrite(filename, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tifffile import imread\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/Fabian/ImageData/CalciumImmunCell/Macrophage/Amputation/c1147x1382_001-MaxIP_s1/Masks_Cellpose/RFP_s01_f0001_z0001.tif'\n",
    "mask = imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/home/Fabian/ImageData/TrackingTestFiles/PipelineTest/1382x1166_15%laser@5min-MaxIP-MaxIP_s1/gnn_files/all_data_df.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "pytorch_path = '/home/Fabian/ImageData/TrackingTestFiles/PipelineTest/1382x1166_15%laser@5min-MaxIP-MaxIP_s1/gnn_files/pytorch_geometric_data.pt'\n",
    "edge_index = torch.load(pytorch_path).edge_index\n",
    "output_path = '/home/Fabian/ImageData/TrackingTestFiles/PipelineTest/1382x1166_15%laser@5min-MaxIP-MaxIP_s1/gnn_files/raw_output.pt'\n",
    "output_pred = torch.load(output_path)\n",
    "outputs = output_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_threshold = 0.4\n",
    "frame_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_indices = df[df.frame_num==frame_ind].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([365123, 794621]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(outputs_hard.bool(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_soft = torch.sigmoid(outputs)\n",
    "outputs_hard = (outputs_soft > decision_threshold).int()\n",
    "connected_indices = edge_index[:, outputs_hard.bool()]\n",
    "\n",
    "# ind_place = np.argwhere(connected_indices[0, :] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 794621])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1159744])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34.1735, 28.6891, 28.9476,  ..., 27.8264, 35.9322, 32.3199])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0982136e-08, 1.1442487e-08, 1.3596248e-08, ..., 9.9999976e-01,\n",
       "       9.9999988e-01, 1.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(outputs_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1159744])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1159744])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_hard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 794621])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32000 in connected_indices[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3817"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, count = np.unique(connected_indices[1,:],return_counts=True)\n",
    "np.argmax(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_place=tensor([[259]])\n",
      "next_frame_ind=tensor([126])\n"
     ]
    }
   ],
   "source": [
    "i = 115\n",
    "ind_place = np.argwhere(connected_indices[0, :] == i)\n",
    "print(f'{ind_place=}')\n",
    "next_frame_ind = connected_indices[1, ind_place][0]\n",
    "print(f'{next_frame_ind=}')\n",
    "\n",
    "next_node_ind=126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition=tensor([False, False, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "condition = connected_indices[1,:] == next_node_ind #delete already assigned nodes from the list to avoid several cells with the same ID per frame\n",
    "print(f'{condition=}')\n",
    "# connected_indices = connected_indices[:,~condition] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20864])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_indices[:,~condition].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20866])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.array([127.28314892, 116.10340219, 189.21152185, 251.84916121,\n",
    "        77.0584194 , 461.74126954, 329.67408148, 293.62050337,\n",
    "       125.67020331, 244.59149617,  60.53924347, 496.00403224,\n",
    "       616.00324674, 423.0295498 ,  14.56021978, 360.03472055,\n",
    "       522.06129908, 272.09005862,  39.29376541, 391.15470085,\n",
    "       294.24479605, 554.23099877,  21.26029163,  28.60069929,\n",
    "       419.26841045, 329.38882798, 107.68936809, 460.57464107,\n",
    "       492.44796679,  55.15432893,  81.32035416, 137.29530218,\n",
    "        24.18677324, 409.0293388 , 258.41439588, 568.64136325,\n",
    "       365.23417146, 284.80344099,  96.76776323, 643.89828389,\n",
    "       472.29863434, 302.03476621, 173.76996288,  36.40054945,\n",
    "       532.08739884, 512.19722764, 609.18634259, 214.57399656,\n",
    "       458.57714727, 566.34441818, 124.91997438, 293.1705988 ,\n",
    "       148.76155417, 238.47851056, 348.91402953,  63.03173804,\n",
    "        49.64876635,  44.01136217,  46.87216658,  82.97590012,\n",
    "       153.57408636, 218.13069477, 665.53211793, 633.84619586,\n",
    "        59.03388857, 166.76930173, 485.50695155, 601.63111622,\n",
    "        74.70609078,  87.00574694, 399.18542058, 291.52872929,\n",
    "       207.28000386, 440.91835979, 265.66332077, 101.98039027,\n",
    "       180.70141117, 550.553358  , 363.04407446, 240.35390573,\n",
    "       664.71121549,  78.77182237, 466.09226554, 134.01492454,\n",
    "       503.88292291, 101.59724406, 121.69634341, 305.26218239,\n",
    "       263.1083427 , 621.83679531, 381.76039606, 423.88323864,\n",
    "       203.03940504, 640.6403047 , 601.23622645, 230.58620947,\n",
    "       327.48282398,  96.56603958, 657.05098737, 271.18443908,\n",
    "       116.21101497, 538.18398341, 240.75090862, 105.84894898,\n",
    "       569.84296082, 259.61702564, 453.84248369, 496.44838604,\n",
    "       168.66831356, 260.86394921, 157.03502794, 368.43588316,\n",
    "       290.79889959, 220.91174708, 397.80020111, 331.76648414,\n",
    "       186.46179233, 236.79949324, 634.07649381, 152.30561382,\n",
    "       143.60013928, 258.04844506, 194.28072473, 439.00455579,\n",
    "       185.15128949, 290.29123307, 666.08257746, 315.79265349,\n",
    "       252.43811123, 136.88316186, 468.00213675, 558.4012894 ,\n",
    "       267.05991837, 532.8508234 , 392.13518077, 239.45354456,\n",
    "       613.29356755, 597.64956287, 263.82190963, 581.4894668 ,\n",
    "       229.13969538, 199.06029237, 505.79936734, 386.00518131,\n",
    "       355.62058433, 209.60200381, 161.71889191, 220.86421168,\n",
    "       255.72641631, 432.33436135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mask = distance < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_distance = distance[distance_mask]\n",
    "min_index = np.argmin(filtered_distance)\n",
    "nearest_cell = np.where(distance_mask)[0][min_index]\n",
    "nearest_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_distance.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = connected_indices[1,:] == 2033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_indices = connected_indices[:,~condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(connected_indices[1,:]==2033)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "next_node_ind = -2\n",
    "mitosis = False\n",
    "if not mitosis and not next_node_ind==-1:\n",
    "    print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n",
      "tensor([2024, 2031])\n",
      "tensor([2025, 2032])\n",
      "tensor([2028, 2036])\n"
     ]
    }
   ],
   "source": [
    "print(np.where(connected_indices[1,:]==2033))\n",
    "print(connected_indices[:,3817])\n",
    "print(connected_indices[:,3820])\n",
    "print(connected_indices[:,3823])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(outputs_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_first_frame(cell_starts):\n",
    "    cols = [\"child_id\", \"parent_id\", \"start_frame\"]\n",
    "    df_parent = pd.DataFrame(index=range(len(cell_starts)), columns=cols)\n",
    "    df_parent.loc[:, [\"start_frame\", \"parent_id\"]] = 0\n",
    "    df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "    return df_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_in_specific_col(all_frames_traject, frame_ind, curr_node, next_node):\n",
    "    if curr_node in all_frames_traject[frame_ind, :]:\n",
    "        flag = 0\n",
    "        ind_place = np.argwhere(all_frames_traject[frame_ind, :] == curr_node)\n",
    "        if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "            all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "    else:\n",
    "        flag = 1\n",
    "        ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "        while ind_place.size == 0:\n",
    "            new_col = -2 * np.ones((all_frames_traject.shape[0], 1), dtype=all_frames_traject.dtype)\n",
    "            all_frames_traject = np.append(all_frames_traject, new_col, axis=1)\n",
    "            ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -2)\n",
    "        ind_place = ind_place.min()\n",
    "        all_frames_traject[frame_ind, ind_place] = curr_node\n",
    "        if frame_ind + 1 < all_frames_traject.shape[0]:\n",
    "            all_frames_traject[frame_ind + 1, ind_place] = next_node\n",
    "    return flag, all_frames_traject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_indices = edge_index[:, outputs_hard.bool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 12506, 12507, 12508])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_indices[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[206], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_soft = torch.sigmoid(outputs)\n",
    "outputs_hard = (outputs_soft > decision_threshold).int()\n",
    "\n",
    "\n",
    "flag_id0_terminate = False\n",
    "# extract values from arguments\n",
    "connected_indices = edge_index[:, outputs_hard.bool()]\n",
    "\n",
    "\n",
    "# find number of frames for iterations\n",
    "frame_nums, counts = np.unique(df.frame_num, return_counts=True)\n",
    "all_frames_traject = np.zeros((frame_nums.shape[0], counts.max())) #crearing matrix with shape (rows=frames, column=max num of label in frame)\n",
    "\n",
    "# intialize the matrix with -2 meaning empty cell, -1 means end of trajectory,\n",
    "# other value means the number of node in the graph\n",
    "all_frames_traject[:, :] = -2\n",
    "all_trajectory_dict = {}\n",
    "str_track = ''\n",
    "df_parents = []\n",
    "\n",
    "for frame_ind in frame_nums: \n",
    "    nodes_indices = df[df.frame_num==frame_ind].index.values # find the places containing frame_ind\n",
    "    next_frame_indices = np.array([])\n",
    "    \n",
    "    if frame_ind == 0:  # for the first frame, we should fill the first row with node indices\n",
    "        all_frames_traject[frame_ind, :nodes_indices.shape[0]] = nodes_indices\n",
    "        df_parents.append(fill_first_frame(nodes_indices))\n",
    "    \n",
    "    num_starts = 0\n",
    "    cell_starts = []\n",
    "    \n",
    "    for i in nodes_indices:\n",
    "        if i in connected_indices[0, :]:\n",
    "            ind_place = np.argwhere(connected_indices[0, :] == i)\n",
    "            #check how many potential connections one cell has\n",
    "            if ind_place.shape[-1] > 1: # if more than one connection is possible:\n",
    "                next_frame_ind = connected_indices[1, ind_place].numpy().squeeze() #get the ID of the potential cells in the next frame\n",
    "            \n",
    "                next_frame = df.loc[next_frame_ind, [\"centroid_row\", \"centroid_col\"]].values #getting the centroid position for the potential connection points\n",
    "                curr_node = df.loc[i, [\"centroid_row\", \"centroid_col\"]].values #getting the original centroid\n",
    "\n",
    "                distance = np.sqrt(((next_frame - curr_node) ** 2).sum(axis=-1)) #get the euclidean distance between the node and the possible cells to connect\n",
    "                nearest_cell = np.argmin(distance, axis=-1) #get the index of the closest cell\n",
    "                # add to the array\n",
    "                next_node_ind = next_frame_ind[nearest_cell]\n",
    "\n",
    "            elif ind_place.shape[-1] == 1:  # one node in the next frame is connected to current node\n",
    "                next_node_ind = connected_indices[1, ind_place[0]]\n",
    "            else:  # no node in the next frame is connected to current node -\n",
    "                # in this case we end the trajectory\n",
    "                next_node_ind = -1\n",
    "        else:\n",
    "            # we dont find the current node in the edge indices matrix - meaning we dont have a connection\n",
    "            # for the node - in this case we end the trajectory and the cell\n",
    "            if i == 0:\n",
    "                flag_id0_terminate = True\n",
    "            next_node_ind = -1                \n",
    "        next_frame_indices = np.append(next_frame_indices, next_node_ind) #add the next node index or -1 for track stop into the next_frame_indices list\n",
    "        # count the number of starting trajectories\n",
    "        start, all_frames_traject = insert_in_specific_col(all_frames_traject, frame_ind, i, next_node_ind)\n",
    "        num_starts += start                \n",
    "        \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_node=array([565., 273.])\n",
      "distance=array([ 0.        , 66.09841148])\n",
      "nearest_cell=0\n",
      "next_node_ind=13\n",
      "next_frame_indices=array([13.])\n"
     ]
    }
   ],
   "source": [
    "frame_ind=0\n",
    "df_parents = []\n",
    "nodes_indices = df[df.frame_num==frame_ind].index.values # find the places containing frame_ind\n",
    "next_frame_indices = np.array([])\n",
    "\n",
    "if frame_ind == 0:  # for the first frame, we should fill the first row with node indices\n",
    "    all_frames_traject[frame_ind, :nodes_indices.shape[0]] = nodes_indices\n",
    "    df_parents.append(fill_first_frame(nodes_indices))\n",
    "\n",
    "\n",
    "num_starts = 0\n",
    "cell_starts = []\n",
    "\n",
    "i = nodes_indices[2]\n",
    "\n",
    "\n",
    "if i in connected_indices[0, :]:\n",
    "    ind_place = np.argwhere(connected_indices[0, :] == i)\n",
    "    if ind_place.shape[-1] > 1: # if more than one connection is possible:\n",
    "        next_frame_ind = connected_indices[1, ind_place].numpy().squeeze()\n",
    "        next_frame = df.loc[next_frame_ind, [\"centroid_row\", \"centroid_col\"]].values\n",
    "        curr_node = df.loc[i, [\"centroid_row\", \"centroid_col\"]].values\n",
    "        print(f'{curr_node=}')\n",
    "        distance = np.sqrt(((next_frame - curr_node) ** 2).sum(axis=-1))\n",
    "        print(f'{distance=}')\n",
    "        nearest_cell = np.argmin(distance, axis=-1)\n",
    "        print(f'{nearest_cell=}')\n",
    "        next_node_ind = next_frame_ind[nearest_cell]\n",
    "        print(f'{next_node_ind=}')\n",
    "next_frame_indices = np.append(next_frame_indices, next_node_ind)\n",
    "print(f'{next_frame_indices=}')\n",
    "# count the number of starting trajectories\n",
    "start, all_frames_traject = self.insert_in_specific_col(all_frames_traject, frame_ind, i, next_node_ind)\n",
    "num_starts += start    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_value(value, test_list):\n",
    "    print(value)\n",
    "    print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "blbla\n",
      "80\n",
      "blbla\n",
      "90\n",
      "blbla\n",
      "700\n",
      "blbla\n"
     ]
    }
   ],
   "source": [
    "unique_stuff = np.unique([90,80,700,50,80])\n",
    "test_list = 'blbla'\n",
    "partiaprint = partial(print_value, test_list=test_list)\n",
    "\n",
    "with ThreadPoolExecutor() as executer:\n",
    "    executer.map(partiaprint, np.unique([90,80,700,50,80]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames_traject_path = '/home/Fabian/ImageData/all_frames_traject.csv'\n",
    "all_frames_traject = np.genfromtxt(all_frames_traject_path, delimiter=',')\n",
    "cols = [\"child_id\", \"parent_id\", \"start_frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ind = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "start1 = np.argwhere(all_frames_traject[frame_ind-1, :] == -1)\n",
    "start2 = np.argwhere(all_frames_traject[frame_ind-1, :] == -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_node_ids = all_frames_traject[frame_ind, start1].squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23. 24. 25. 27. 29. 30.]\n"
     ]
    }
   ],
   "source": [
    "cell_starts = start_node_ids[start_node_ids>0]\n",
    "print(cell_starts)\n",
    "cell = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_node_ids = all_frames_traject[frame_ind - 1, ind_place].squeeze(axis=1)\n",
    "df_parent = pd.DataFrame(index=range(len(cell_starts)), columns=cols)\n",
    "df_parent.loc[:, \"start_frame\"] = frame_ind\n",
    "finish_cell = df.loc[finish_node_ids, [\"centroid_row\", \"centroid_col\"]].values\n",
    "curr_cell = df.loc[cell, [\"centroid_row\", \"centroid_col\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16., 18., 14., 15., 19.])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(finish_node_ids,[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.sqrt(((finish_cell - curr_cell) ** 2).sum(axis=-1)) #get the distance from every point\n",
    "distance_mask = distance < self.max_travel_dist #check that distances are inside the max_travel distance\n",
    "filtered_distance = distance[distance_mask] #apply the filter on the array\n",
    "if filtered_distance.size == 0:\n",
    "    df_parent.loc[ind, \"child_id\"] = cell\n",
    "    df_parent.loc[ind, \"parent_id\"] = 0\n",
    "    continue\n",
    "min_index = np.argmin(filtered_distance) #get the smalest distance index in the filtered array\n",
    "nearest_cell = np.where(distance_mask)[0][min_index] #get back the index from the original array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16., 18., 14., 15., 19., 20.])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish_node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 62.20128616, 120.42009799,  64.93843238, 180.62391868,\n",
       "       185.31055016, 233.85679379])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = np.sqrt(((finish_cell - curr_cell) ** 2).sum(axis=-1))\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.array([28,48,800,12,52,364,75])\n",
    "max_dist=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_array = distance < max_dist\n",
    "filtered = distance[masked_array]\n",
    "min_index = np.argmin(filtered)\n",
    "np.where(masked_array)[0][min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.size ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = np.argmin([17,5,7,9,10,18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_frames_traject[frame_ind, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_place = np.argwhere(connected_indices[0, :] == 1)\n",
    "ind_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_frame_ind = connected_indices[1, ind_place][0]#.numpy().squeeze()\n",
    "next_frame_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([358.07541105])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_frame = df.loc[next_frame_ind, [\"centroid_row\", \"centroid_col\"]].values #getting the centroid position for the potential connection points\n",
    "curr_node = df.loc[2033, [\"centroid_row\", \"centroid_col\"]].values #getting the original centroid\n",
    "distance = np.sqrt(((next_frame - curr_node) ** 2).sum(axis=-1))\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_array = distance < max_dist\n",
    "filtered = distance[masked_array]\n",
    "min_index = np.argmin(filtered)\n",
    "nearest_cell = np.where(masked_array)[0][min_index]\n",
    "next_node_ind = int(next_frame_ind[nearest_cell])\n",
    "next_node_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_travel_dist = 100\n",
    "\n",
    "\n",
    "def find_parent_cell(self, frame_ind, all_frames_traject, df, cell_starts):\n",
    "    ind_place = np.argwhere(all_frames_traject[frame_ind, :] == -1) #find all indeces were a track ended\n",
    "    finish_node_ids = all_frames_traject[frame_ind - 1, ind_place].squeeze(axis=1)# find the start IDs in the frame before\n",
    "    # print(f\"frame_ind: {frame_ind}, cell_starts: {cell_starts}, cell_ends: {finish_node_ids}\")\n",
    "\n",
    "    df_parent = pd.DataFrame(index=range(len(cell_starts)), columns=self.cols)\n",
    "    df_parent.loc[:, \"start_frame\"] = frame_ind\n",
    "\n",
    "    if finish_node_ids.shape[0] != 0:\n",
    "        if self.is_3d:\n",
    "            finish_cell = df.loc[finish_node_ids, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "        else:\n",
    "            finish_cell = df.loc[finish_node_ids, [\"centroid_row\", \"centroid_col\"]].values\n",
    "        for ind, cell in enumerate(cell_starts):\n",
    "            if self.is_3d:\n",
    "                curr_cell = df.loc[cell, [\"centroid_depth\", \"centroid_row\", \"centroid_col\"]].values\n",
    "            else:\n",
    "                curr_cell = df.loc[cell, [\"centroid_row\", \"centroid_col\"]].values\n",
    "\n",
    "            distance = ((finish_cell - curr_cell) ** 2).sum(axis=-1)\n",
    "            nearest_cell = np.argmin(distance, axis=-1)\n",
    "            parent_cell = int(finish_node_ids[nearest_cell])\n",
    "            df_parent.loc[ind, \"child_id\"] = cell\n",
    "            df_parent.loc[ind, \"parent_id\"] = parent_cell\n",
    "    else:\n",
    "        df_parent.loc[:, \"child_id\"] = cell_starts\n",
    "        df_parent.loc[:, \"parent_id\"] = 0\n",
    "\n",
    "    return df_parent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_dock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
